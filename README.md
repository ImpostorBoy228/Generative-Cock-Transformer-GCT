# Generative-Cock-Transformer-GCT

A generative Pre-trained Transformer, but generated by itself, introducing brand new Generative Cock Transformer (GCT).

## Features

- Self-generating transformer architecture.
- Integrates pre-trained model: `t5-base` (as of v2.0).
- Designed for experimental NLP tasks and model self-improvement.

## Installation

```bash
git clone https://github.com/ImpostorBoy228/Generative-Cock-Transformer-GCT.git
cd Generative-Cock-Transformer-GCT
pip install -r requirements.txt
```

## Usage

```python
from gct import GenerativeCockTransformer

model = GenerativeCockTransformer(pretrained="t5-base")
output = model.generate("Your input text here")
print(output)
```

## Code Overview

- `gct.py`: Core model logic and architecture.
- `train.py`: Training routines and utilities.
- `requirements.txt`: Python dependencies (transformers, torch, etc).

## Contributing

Pull requests and issues are welcome! Please include tests and clear descriptions.

## License

MIT (see LICENSE file).

## Changelog

- v2.0: Added pre-trained model t5-base.
